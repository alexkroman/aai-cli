"""Voice agent: streaming STT -> LLM -> TTS."""

import asyncio
import json
import os
import threading
import urllib.request

import assemblyai as aai
import anthropic
import uvicorn
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.responses import HTMLResponse

app = FastAPI(title="{title}")

SYSTEM_PROMPT = """{system_prompt}"""
RIME_SPEAKER = "{rime_speaker}"
RIME_MODEL = "{rime_model}"

aai.settings.api_key = os.environ.get("ASSEMBLYAI_API_KEY", "")
ANTHROPIC_API_KEY = os.environ.get("ANTHROPIC_API_KEY", "")
RIME_API_KEY = os.environ.get("RIME_API_KEY", "")

HTML_PAGE = """
<!DOCTYPE html>
<html>
<head>
    <title>{title}</title>
    <style>
        * {{ box-sizing: border-box; }}
        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            max-width: 600px;
            margin: 50px auto;
            padding: 20px;
            background: #f5f5f5;
        }}
        .container {{
            background: white;
            border-radius: 12px;
            padding: 30px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }}
        h1 {{ margin-top: 0; color: #333; }}
        p.desc {{ color: #666; margin-top: -10px; }}
        .status {{
            padding: 15px;
            border-radius: 8px;
            margin: 20px 0;
            font-weight: 500;
        }}
        .status.idle {{ background: #f5f5f5; color: #666; }}
        .status.listening {{ background: #eef; color: #007; }}
        .status.processing {{ background: #ffe; color: #a70; }}
        .status.speaking {{ background: #fef; color: #707; }}
        button {{
            padding: 15px 30px;
            font-size: 18px;
            border: none;
            border-radius: 8px;
            cursor: pointer;
            margin: 5px;
        }}
        button:disabled {{ opacity: 0.5; }}
        #startBtn {{ background: #007bff; color: white; }}
        #stopBtn {{ background: #dc3545; color: white; }}
        .transcript {{
            margin-top: 20px;
            padding: 15px;
            background: #f8f9fa;
            border-radius: 8px;
            min-height: 100px;
            max-height: 300px;
            overflow-y: auto;
        }}
        .transcript p {{ margin: 8px 0; }}
        .user {{ color: #007bff; }}
        .assistant {{ color: #28a745; }}
        .system {{ color: #999; font-size: 12px; }}
        .partial {{ color: #999; font-style: italic; }}
    </style>
</head>
<body>
    <div class="container">
        <h1>{title}</h1>
        <p class="desc">{description}</p>
        <div id="status" class="status idle">Click Start to begin</div>
        <div>
            <button id="startBtn" onclick="start()">Start</button>
            <button id="stopBtn" onclick="stop()" disabled>Stop</button>
        </div>
        <div class="transcript" id="transcript"></div>
    </div>
    <script>
        let ws, inputCtx, outputCtx, stream, processor;
        let audioQueue = [], playing = false;

        async function start() {{
            stream = await navigator.mediaDevices.getUserMedia({{
                audio: {{ echoCancellation: true, noiseSuppression: false, autoGainControl: false }}
            }});
            inputCtx = new AudioContext({{ sampleRate: 16000 }});
            outputCtx = new AudioContext({{ sampleRate: 48000 }});
            const src = inputCtx.createMediaStreamSource(stream);
            processor = inputCtx.createScriptProcessor(512, 1, 1);

            ws = new WebSocket(
                `${{location.protocol === 'https:' ? 'wss:' : 'ws:'}}//${{location.host}}/ws`
            );
            ws.binaryType = 'arraybuffer';

            ws.onopen = () => {{
                document.getElementById('startBtn').disabled = true;
                document.getElementById('stopBtn').disabled = false;
                processor.onaudioprocess = e => {{
                    if (ws.readyState !== 1) return;
                    const f = e.inputBuffer.getChannelData(0);
                    const i = new Int16Array(f.length);
                    for (let j = 0; j < f.length; j++)
                        i[j] = Math.max(-32768, Math.min(32767, f[j] * 32768));
                    ws.send(i.buffer);
                }};
                src.connect(processor);
                processor.connect(inputCtx.destination);
            }};

            ws.onmessage = e => {{
                if (typeof e.data === 'string') {{
                    const m = JSON.parse(e.data);
                    if (m.type === 'state') setStatus(m.state);
                    else if (m.type === 'partial') updatePartial(m.content);
                    else if (m.type === 'user_text') {{ clearPartial(); addText('user', m.content); }}
                    else if (m.type === 'text') addText('assistant', m.content);
                    else if (m.type === 'interrupted') {{ audioQueue = []; playing = false; }}
                    else if (m.type === 'error') addText('system', 'Error: ' + m.content);
                }} else {{
                    audioQueue.push(e.data);
                    if (!playing) playNext();
                }}
            }};

            ws.onclose = () => cleanup();
        }}

        function setStatus(s) {{
            const el = document.getElementById('status');
            el.className = 'status ' + s;
            const labels = {{
                idle: 'Ready', listening: 'Listening...',
                processing: 'Thinking...', speaking: 'Speaking...'
            }};
            el.textContent = labels[s] || s;
        }}

        function updatePartial(text) {{
            const el = document.getElementById('transcript');
            let p = document.getElementById('partial');
            if (!p) {{
                p = document.createElement('p');
                p.id = 'partial';
                p.className = 'partial';
                el.appendChild(p);
            }}
            p.textContent = 'You: ' + text;
            el.scrollTop = el.scrollHeight;
        }}

        function clearPartial() {{
            const p = document.getElementById('partial');
            if (p) p.remove();
        }}

        function addText(role, text) {{
            const p = document.createElement('p');
            p.className = role;
            const prefix = role === 'user' ? 'You: ' : role === 'assistant' ? 'Assistant: ' : '';
            p.textContent = prefix + text;
            const el = document.getElementById('transcript');
            el.appendChild(p);
            el.scrollTop = el.scrollHeight;
        }}

        async function playNext() {{
            if (!audioQueue.length) {{ playing = false; return; }}
            playing = true;
            const buf = audioQueue.shift();
            const i16 = new Int16Array(buf), f32 = new Float32Array(i16.length);
            for (let j = 0; j < i16.length; j++) f32[j] = i16[j] / 32768;
            const ab = outputCtx.createBuffer(1, f32.length, 48000);
            ab.getChannelData(0).set(f32);
            const s = outputCtx.createBufferSource();
            s.buffer = ab;
            s.connect(outputCtx.destination);
            s.onended = playNext;
            s.start();
        }}

        function stop() {{ if (ws) ws.close(); cleanup(); }}

        function cleanup() {{
            document.getElementById('startBtn').disabled = false;
            document.getElementById('stopBtn').disabled = true;
            if (processor) processor.disconnect();
            if (stream) stream.getTracks().forEach(t => t.stop());
            if (inputCtx) inputCtx.close();
            if (outputCtx) outputCtx.close();
            audioQueue = []; playing = false;
            setStatus('idle');
        }}
    </script>
</body>
</html>
"""


@app.get("/")
async def index():
    return HTMLResponse(HTML_PAGE)


@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    loop = asyncio.get_event_loop()
    send_lock = asyncio.Lock()
    history = []
    client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY or None)

    async def safe_send_json(data):
        async with send_lock:
            try:
                await websocket.send_json(data)
            except Exception:
                pass

    async def safe_send_bytes(data):
        async with send_lock:
            try:
                await websocket.send_bytes(data)
            except Exception:
                pass

    def process_response(text):
        asyncio.run_coroutine_threadsafe(
            safe_send_json({{"type": "state", "state": "processing"}}), loop
        )

        history.append({{"role": "user", "content": text}})
        response = client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=200,
            system=SYSTEM_PROMPT,
            messages=list(history),
        )
        reply = response.content[0].text
        history.append({{"role": "assistant", "content": reply}})

        asyncio.run_coroutine_threadsafe(
            safe_send_json({{"type": "text", "content": reply}}), loop
        )
        asyncio.run_coroutine_threadsafe(
            safe_send_json({{"type": "state", "state": "speaking"}}), loop
        )

        body = json.dumps({{
            "text": reply,
            "speaker": RIME_SPEAKER,
            "modelId": RIME_MODEL,
            "samplingRate": 48000,
        }}).encode()
        req = urllib.request.Request(
            "https://users.rime.ai/v1/rime-tts",
            data=body,
            headers={{
                "Authorization": f"Bearer {{RIME_API_KEY}}",
                "Content-Type": "application/json",
                "Accept": "audio/pcm",
            }},
        )
        with urllib.request.urlopen(req) as resp:
            audio_bytes = resp.read()

        chunk_size = 48000 * 2
        for i in range(0, len(audio_bytes), chunk_size):
            asyncio.run_coroutine_threadsafe(
                safe_send_bytes(audio_bytes[i : i + chunk_size]), loop
            )

        asyncio.run_coroutine_threadsafe(
            safe_send_json({{"type": "state", "state": "listening"}}), loop
        )

    def on_data(transcript):
        if isinstance(transcript, aai.RealtimePartialTranscript):
            text = transcript.text.strip()
            if text:
                asyncio.run_coroutine_threadsafe(
                    safe_send_json({{"type": "partial", "content": text}}), loop
                )
        elif isinstance(transcript, aai.RealtimeFinalTranscript):
            text = transcript.text.strip()
            if text:
                asyncio.run_coroutine_threadsafe(
                    safe_send_json({{"type": "interrupted"}}), loop
                )
                asyncio.run_coroutine_threadsafe(
                    safe_send_json({{"type": "user_text", "content": text}}), loop
                )
                threading.Thread(
                    target=process_response, args=(text,), daemon=True
                ).start()

    def on_error(error):
        asyncio.run_coroutine_threadsafe(
            safe_send_json({{"type": "error", "content": str(error)}}), loop
        )

    transcriber = aai.RealtimeTranscriber(
        sample_rate=16000,
        on_data=on_data,
        on_error=on_error,
    )
    transcriber.connect()

    await safe_send_json({{"type": "state", "state": "listening"}})

    try:
        while True:
            data = await websocket.receive_bytes()
            transcriber.stream(data)
    except WebSocketDisconnect:
        pass
    finally:
        transcriber.close()


if __name__ == "__main__":
    uvicorn.run(app, host="127.0.0.1", port=8000)
